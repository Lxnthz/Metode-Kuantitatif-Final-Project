{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.linalg import inv\n",
    "from IPython.display import display\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fecth data and filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = 'Crypto.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def convert_to_float(value):\n",
    "    if isinstance(value, str):\n",
    "        return float(value.replace(',', ''))\n",
    "    return float(value)\n",
    "\n",
    "# Convert the 'marketcap' column to float\n",
    "df['marketcap'] = df['marketcap'].apply(convert_to_float)\n",
    "\n",
    "# Set pandas display options to avoid scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Convert all relevant columns to numeric\n",
    "features = ['volume24hrs', 'marketcap', 'circulatingsupply', 'maxsupply', 'totalsupply', 'price']\n",
    "for feature in features:\n",
    "    df[feature] = pd.to_numeric(df[feature], errors='coerce')\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "data_selected = df[features].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers using Z-score\n",
    "def remove_outliers_zscore(data, threshold=3):\n",
    "    z_scores = np.abs(zscore(data))\n",
    "    non_outliers = (z_scores < threshold).all(axis=1)\n",
    "    filtered_data = data[non_outliers]\n",
    "    return filtered_data\n",
    "\n",
    "# Remove outliers\n",
    "data_selected_no_outliers = remove_outliers_zscore(data_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF Calculation for Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate VIF using correlation matrix\n",
    "def calculate_vif(data):\n",
    "    vif = pd.DataFrame()\n",
    "    vif['Feature'] = data.columns\n",
    "    corr_matrix = np.corrcoef(data, rowvar=False)\n",
    "    inv_corr_matrix = inv(corr_matrix)\n",
    "    vif['VIF'] = [inv_corr_matrix[i, i] for i in range(inv_corr_matrix.shape[0])]\n",
    "    return vif\n",
    "\n",
    "# Calculate VIF for original data\n",
    "vif_original = calculate_vif(data_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "x = StandardScaler().fit_transform(data_selected_no_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF Calculation for PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA transformation\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "pca_df = pd.DataFrame(data=principalComponents, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Correlation heatmap for original data\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data_selected.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix (Original Data)')\n",
    "plt.show()\n",
    "\n",
    "# Calculate VIF for PCA data\n",
    "vif_pca = calculate_vif(pca_df)\n",
    "\n",
    "# Correlation heatmap for PCA data\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(pca_df.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix (PCA Data)')\n",
    "plt.show()\n",
    "\n",
    "# Display VIF before and after PCA\n",
    "print(\"VIF for Original Data:\")\n",
    "display(vif_original)\n",
    "print(\"VIF for PCA Data:\")\n",
    "display(vif_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biplot Visualization for PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biplot function\n",
    "def biplot(pca, principalComponents, feature_names):\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    scatter = ax.scatter(principalComponents[:, 0], principalComponents[:, 1])\n",
    "    for i in range(len(feature_names)):\n",
    "        ax.arrow(0, 0, pca.components_[0, i] * max(principalComponents[:, 0]), \n",
    "                 pca.components_[1, i] * max(principalComponents[:, 1]),\n",
    "                 head_width=0.05, head_length=0.1, fc='r', ec='r')\n",
    "        ax.text(pca.components_[0, i] * max(principalComponents[:, 0]), \n",
    "                pca.components_[1, i] * max(principalComponents[:, 1]),\n",
    "                feature_names[i], color='black', ha='center', va='center')\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_title('PCA Biplot')\n",
    "    plt.show()\n",
    "\n",
    "# Display Biplot\n",
    "biplot(pca, principalComponents, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-means clustering\n",
    "def find_optimal_k(data):\n",
    "    inertia = []\n",
    "    silhouette_scores = []\n",
    "    K = range(2, 11)\n",
    "    for k in K:\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(data)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "        silhouette_scores.append(silhouette_score(data, kmeans.labels_))\n",
    "    return K, inertia, silhouette_scores\n",
    "\n",
    "# Optimal k for PCA data\n",
    "K, inertia, silhouette_scores = find_optimal_k(principalComponents)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(K, inertia, marker='o', label='Inertia')\n",
    "plt.plot(K, silhouette_scores, marker='s', label='Silhouette Score')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.title('Elbow Method and Silhouette Score for PCA Data')\n",
    "plt.show()\n",
    "\n",
    "# Apply K-means with optimal k (e.g., k=4)\n",
    "optimal_k = 4\n",
    "kmeans = KMeans(n_clusters=optimal_k)\n",
    "clusters_pca = kmeans.fit_predict(principalComponents)\n",
    "\n",
    "# Add clusters to DataFrame\n",
    "pca_df['cluster'] = clusters_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means Accuracy Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print cluster details\n",
    "def print_cluster_details(kmeans, data, clusters):\n",
    "    n_clusters = kmeans.n_clusters\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    labels = kmeans.labels_\n",
    "    cluster_sizes = pd.Series(clusters).value_counts().sort_index()\n",
    "\n",
    "    print(f\"K-means clustering with {n_clusters} clusters:\")\n",
    "    print(f\"Cluster sizes: {cluster_sizes.values}\")\n",
    "    print(\"\\nCluster means:\")\n",
    "    cluster_means = pd.DataFrame(cluster_centers, columns=data.columns)\n",
    "    display(cluster_means)\n",
    "    \n",
    "    print(\"\\nClustering vector:\")\n",
    "    for i in range(n_clusters):\n",
    "        print(f\"Cluster {i + 1}:\")\n",
    "        print(np.where(labels == i)[0])\n",
    "\n",
    "    within_cluster_ss = kmeans.inertia_\n",
    "    total_ss = np.sum((data - data.mean(axis=0)) ** 2).sum()\n",
    "    between_ss = total_ss - within_cluster_ss\n",
    "    print(\"\\nWithin cluster sum of squares by cluster:\")\n",
    "    print(within_cluster_ss)\n",
    "    print(f\"(between_ss / total_ss = {between_ss / total_ss * 100:.1f}%)\")\n",
    "\n",
    "# Print cluster details for with PCA\n",
    "print(\"\\nK-means clustering with PCA\")\n",
    "print_cluster_details(kmeans, pca_df[['PC1', 'PC2']], clusters_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Data for Best Dendograms using Cophenetic Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cophenetic correlation for different linkage methods\n",
    "linkage_methods = ['single', 'complete', 'average', 'ward']\n",
    "cophenetic_scores = {}\n",
    "\n",
    "for method in linkage_methods:\n",
    "    Z = linkage(x, method=method)\n",
    "    coph_corr, _ = cophenet(Z, pdist(x))\n",
    "    cophenetic_scores[method] = coph_corr\n",
    "\n",
    "# Display cophenetic scores\n",
    "cophenetic_df = pd.DataFrame(list(cophenetic_scores.items()), columns=['Linkage Method', 'Cophenetic Correlation'])\n",
    "display(cophenetic_df)\n",
    "\n",
    "# Select the best method\n",
    "best_method = max(cophenetic_scores, key=cophenetic_scores.get)\n",
    "print(f\"The best linkage method is: {best_method} with a cophenetic correlation of {cophenetic_scores[best_method]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dendogram Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Clustering\n",
    "linked = linkage(principalComponents, 'average')\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked, orientation='top', truncate_mode='lastp', p=optimal_k)\n",
    "plt.title('Dendrogram for PCA Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter Plot for PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of clusters\n",
    "def scatter_plot(data, x_feature, y_feature, clusters):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.scatterplot(data=data, x=x_feature, y=y_feature, hue=clusters, palette='viridis')\n",
    "    plt.title(f'Scatter Plot: {x_feature} vs {y_feature}')\n",
    "    plt.xlabel(x_feature)\n",
    "    plt.ylabel(y_feature)\n",
    "    plt.legend(title='Cluster')\n",
    "    plt.show()\n",
    "\n",
    "# Since PCA data is already reduced, we will use PC1 and PC2 for visualization\n",
    "scatter_plot(pca_df, 'PC1', 'PC2', 'cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusterization Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display PCA data with clusters\n",
    "print(\"PCA Data with Clusters:\")\n",
    "display(pca_df)\n",
    "\n",
    "# Display original data with clusters\n",
    "data_selected_no_outliers['cluster'] = clusters_pca\n",
    "print(\"Original Data with Clusters:\")\n",
    "display(data_selected_no_outliers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
